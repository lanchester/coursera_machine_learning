## ニューラルネットワークのモデル表現1

<img width="963" alt="2016-07-19 20 29 57" src="https://cloud.githubusercontent.com/assets/6447085/16948435/9ccf9484-4def-11e6-9bd3-921573af1425.png">

ニューラルネットワークは脳のニューロンを模している。ニューロンは細胞核と情報をインプットする入力ワイヤ、他のニューロンに情報を伝達する出力ワイヤを持っている

### 脳内のニューロン

<img width="960" alt="2016-07-19 20 31 36" src="https://cloud.githubusercontent.com/assets/6447085/16948478/d3d9e97a-4def-11e6-89a7-10e359547951.png">

ニューロンは他のニューロンに電気パルスを送り情報を伝える。これは筋肉の収縮や視覚などのセンサーも同様である。

### ニューロンモデル: ロジスティック単位

<img width="961" alt="2016-07-19 20 32 52" src="https://cloud.githubusercontent.com/assets/6447085/16948515/17402044-4df0-11e6-9e58-f8f220497e66.png">

ニューロンの学習モデルを簡略化すると、複数の入力ワイヤからフィーチャーを受け取り学習を行った後、 $h_\theta(x) \frac{1}{1 + e^{-\theta^Tx}}$ を出力する、という風になる

ニューロンへの入力は入力ノードのみを $x_1$ から書くが、そう記したほうが便利な場合に限り $x_0 = 1$ をバイアスユニット、またはバイアスニューロンとして書くことがある

この人工的ニューロンによって導かれるシグモイド関数をアクティベート関数と呼ぶ。またモデルのパラメータ $\theta$ をウェイトと呼ぶことがある。

### ニューラルネットワーク

<img width="960" alt="2016-07-19 20 35 49" src="https://cloud.githubusercontent.com/assets/6447085/16948593/83d87d3c-4df0-11e6-81ca-e67856d930c1.png">

ニューラルネットワークとはニューロンが集まったグループのこと。

フィーチャーを入力する入力レイヤー、仮説による最終結果を出力する出力レイヤー、その中間を隠れたレイヤー(hidden layer)と言う。

<img width="961" alt="2016-07-19 20 37 56" src="https://cloud.githubusercontent.com/assets/6447085/16948636/c86826fa-4df0-11e6-9272-cb82b9fb9f20.png">

$a_i^{(j)}$ はjレイヤーのi番目のユニットを表す。
$\theta^{(j)}$ はレイヤー $j$ からレイヤー $j+1$ にマッピングする関数を制御するパラメータの行列。

隠れたレイヤーが2層目、出力レイヤーが3層目とするならば、それぞれのユニットの関数は
$$
a_1^{(2)} = g(\theta_1^{(1)T}x)
$$
$$
a_2^{(2)} = g(\theta_2^{(1)T}x)
$$
$$
a_3^{(2)} = g(\theta_3^{(1)T}x)
$$
$$
h_\theta(x) = a_1^{(3)} = g(\theta_1^{(2)T}a)
$$
とあらわされる。

$j$ レイヤーに $s_j$ 個のユニットがある時、 $j+1$レイヤーには $s_{j+1}$ 個のユニットがあり、この時 $\theta^{(j)}$ は $s_{j+1}×(s_j + 1)$ 次元の行列になる。
