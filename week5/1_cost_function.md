# ニューラルネットワーク学習

## コスト関数

### ニューラルネットワーク(分類)

![2016-07-26 16 05 02](https://cloud.githubusercontent.com/assets/6447085/17128923/e69fec66-534a-11e6-8157-bb58af6bc5b3.png)

$L$ レイヤー総数
$s_l$ $l$ レイヤーのユニット数　とする。

バイナリ分類ではデータセットの $y$ は0か1、マルチクラス分類では $K$ クラスの分類なら $K$ 次元ベクトルになり、 $s_l$ は$K$ になる。 (edited)

バイナリ分類の場合も式の簡略のため $K = 1$ とおく。

### コスト関数

![2016-07-26 16 07 06](https://cloud.githubusercontent.com/assets/6447085/17128952/09dfa734-534b-11e6-9e67-51c93ea4d52a.png)

ニューラルネットワークのコスト関数は分類では一つだったコスト関数が、 $K$ ユニットある状態を一般化したものになる。

前半の項は分類の仮説と比べてニューラルネットワークの仮説は $K$ ユニットあるため1から $K$ までの和をとっている。後半の正規化項では隠れレイヤのユニットを含めた全てのパラメータの二乗の和をとっている。但しバイアスユニットのパラメータは除くことが多い。
