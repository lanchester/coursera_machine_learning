## バックプロパゲーション

### 勾配計算

![2016-07-26 16 08 08](https://cloud.githubusercontent.com/assets/6447085/17128974/2ef7a594-534b-11e6-9875-30079c3e262b.png)

ニューラルネットワークのコスト関数を最小化するには $J(\theta)$ と 偏微分項 $\frac{\delta }{\delta \theta _{ij}^{(l)}}J(\theta )$ を求める必要がある。


### バックプロパゲーション

![2016-07-26 16 08 54](https://cloud.githubusercontent.com/assets/6447085/17128982/478d9d3e-534b-11e6-8e13-74a48b5bab82.png)

フォワードプロパゲーションの場合は一つ前のレイヤーの各ユニットのアクティベート関数の和を次のレイヤーの各ユニットへの入力値としていった。

![2016-07-26 16 10 25](https://cloud.githubusercontent.com/assets/6447085/17129022/7ddf7e16-534b-11e6-824b-4c72ec41a666.png)

偏微分項を求めるにはバックプロパゲーションというアルゴリズムを用いる。

$l$ レイヤーの $j$ 番目のノードの誤差を $\delta_j^{(l)}$ とする。これは各ユニットのアクティベート関数の誤差がどの程度かを表している。

まず
$$
\delta_j^{(4)} = a_j^{(4)} - y_j
$$
を求める。$a_j^{(4)}$ は出力レイヤのアクティベート関数なので $(h_\theta(x))j$ とも書ける。$ \delta_j^{(4)} $ の式は $(h_\theta(x))j$ や $y_j$ が実数でもベクトルでも成立する。ベクトルの場合は $\delta^{(4)} = a^{(4)} - y$ となる。

このレイヤー毎の $ \delta $ をレイヤーを遡って求めていく。
$$
\delta^{(3)} = (\theta^{(3)})^T\delta^{(4)}.*g'(z(3)) \\
\delta^{(2)} = (\theta^{(2)})^T\delta^{(3)}.*g'(z(2))
$$
$.*$ は要素毎の積の意味。$\delta,　\theta,　z$ はベクトルである。

$g'$ は微分で $g'(z(3)) = a^{(3)}.*(1 - a^{(3)})$ となる。$a$ はベクトルで、この1も全要素が1のベクトルを表している。

$\delta^{(1)}$ は存在しない。レイヤ1は入力なのでその値は変更したくないため。

このプロセスをバックプロパゲーションという。この$\delta$ を求めることで $J(\theta)$ の偏微分項を求めることができる。

### バックプロパゲーション

![2016-07-26 16 11 43](https://cloud.githubusercontent.com/assets/6447085/17129044/ad21880e-534b-11e6-8c81-7753eaec533b.png)


$\delta$ を求めるプロセスを使ってニューラルネットワークのコスト関数最小化アルゴリズムを実装できる。

$m$ 個のトレーニングセットがある時、
$\Delta_{ij}^{(l)} = 0$ の初期値を代入する。
次に1から $m$ 回のループにおいて
1. $a^{(1)} = x^{(i)}$ を初期値にいれる
2. $a^{(1)}$ をフォ ワードプロパゲーションさせ $a^{(L)}$ を求める
3. $\delta^{(L)} = a^{(L)} - y^{(i)}$ を求める
4. バックプロパゲーションにより$\delta^{(L - 1)},  \delta^{(L - 2)},...\delta^{(2)}$ までをを求める
5. $\Delta_{ij}^{(l)} := \Delta_{ij}^{(l)} + a_j^{(l)}\delta_i^{(l-1)} $ を求める

5. の式は $i,j$ の各数値に対して更新をしているので、これをベクトル化すると
$$
\Delta^{(l)} := \Delta^{(l)} + \delta^{(l + 1)}(a^{(l)})^T
$$
となる。

ループを抜けたあとで計算される $D_{ij}^{(l)}$ の値はコスト関数の偏微分となることが証明されている。この値を用いて最急降下法を適用することができる。
