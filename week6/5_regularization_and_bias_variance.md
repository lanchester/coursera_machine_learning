## 正規化とバイアス／バリアンス

### 正規化された線形回帰

![2016-08-01 15 41 54](https://cloud.githubusercontent.com/assets/6447085/17285586/8a12cf3c-57fe-11e6-8dbe-482230a236c8.png)

正規化項 $\lambda$ が大きいほどアンダーフィットする。逆に0ならオーバーフィットする。

### 正規化パラメータ $\lambda$ の選び方

![2016-08-01 15 42 51](https://cloud.githubusercontent.com/assets/6447085/17285611/b1e6bc4e-57fe-11e6-9719-028d944a900a.png)

正規化項のある本来のコスト関数 $J(\theta)$ とは別に、トレーニングセットによる $J_{train}(\theta)$ を正規化項なしで定義する。

同様にクロスバリデーションセットによる $J_{cv}(\theta)$ 、テストセットによる $J_{test}(\theta)$ を定義する。これらから $\lambda$ を自動的に求める。

### 正規化パラメータ $\lambda$ の選び方

![2016-08-01 15 43 50](https://cloud.githubusercontent.com/assets/6447085/17285619/c3e26d94-57fe-11e6-8461-bebb8c37d6d7.png)

まずあらかじめ試したい $\lambda$ の値をいくつか用意する。用意した $\lambda$ を使ってコスト関数を最小化し、得られたパラメータ  $\theta$ を使ってクロスバリデーションセットによるコスト関数の誤差を見る。そして一番小さいものを選ぶ。さらに試す場合はテストセットの誤差がどの程度かを確認する。

### バイアス／バリアンスとしての $\lambda$ の関数

![2016-08-01 15 44 35](https://cloud.githubusercontent.com/assets/6447085/17285634/df3fed32-57fe-11e6-8661-ca6d62c3b215.png)

$J_{train}(\theta)$ は元々 $\lambda$ がそれほど大きくない値でフィットしていたので $\lambda$ が小さい時は誤差が小さい。 $\lambda$ が大きくなるにつれてアンダーフィット(高バイアス)となり誤差が大きくなる。一方クロスバリデーションセットの場合は、 $\lambda$ が小さいとオーバーフィット(高バリアンス)となり、大きくしていくとちょうどよい値で誤差が最小になった後また増えていく。

実際のグラフはこれほど綺麗にはならずノイズが混じる。
