## 仮説の選択とトレーニング/バリデーション/テストセット

### オーバーフィッティング例

![2016-08-01 15 32 37](https://cloud.githubusercontent.com/assets/6447085/17285355/334a63a0-57fd-11e6-8fde-894dffa7b414.png)

仮説がトレーニングセットにフィットしているからといって、良い仮説とは限らない。

## 仮説選択

![2016-08-01 15 33 51](https://cloud.githubusercontent.com/assets/6447085/17285402/60cd819a-57fd-11e6-8116-27e2877cf4c3.png)


多項式の次数をいくつにするか決定する時、1次を $\theta^{(1)}$、2次を $\theta^{(2)}$ ... としてそれぞれの多項式のコスト関数を $J_{test}(\theta^{(1)})$ のように表す。

dを多項式の次数としてパラメータ $\theta$ の他にdも追加され、それもデータセットを用いて決定したいと考える。$d = 1,...10$ のモデルに対パラメータをフィッティングし、それぞれの仮説によるテストセットとの誤差を計測し、その値が小さいものを選ぶ。

ここでフィッティングのために使ったテストセットで誤差を計測しようとしても正しい誤差は測定できない。

### 仮説を評価する

![2016-08-01 15 35 06](https://cloud.githubusercontent.com/assets/6447085/17285429/9103d76a-57fd-11e6-8f29-e8f94a7d34f2.png)

データセットを3つにわける。1つ目はトレーニングセット、2つ目はクロスバリデーションセット、3つ目はテストセット。6:2:2の比率。

### トレーニング/バリデーション/テスト誤差

![2016-08-01 15 35 48](https://cloud.githubusercontent.com/assets/6447085/17285448/afdbc346-57fd-11e6-9413-53ef884e5b34.png)

トレーニング誤差は今までのコスト関数とほぼ一致する。クロスバリデーション誤差も同じである。テスト誤差は前のスライドで見た通り。

### モデル選択

![2016-08-01 15 36 46](https://cloud.githubusercontent.com/assets/6447085/17285462/ca3cbd44-57fd-11e6-9c62-74ac6c28be08.png)

モデル選択時の誤差の測定はクロスバリデーションの誤差を見る。
