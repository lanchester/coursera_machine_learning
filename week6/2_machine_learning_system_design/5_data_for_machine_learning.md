## 機械学習のデータ

### 高精度な機械学習デザイン

<img width="964" alt="2016-08-08 14 18 12" src="https://cloud.githubusercontent.com/assets/6447085/17469937/f802c708-5d72-11e6-8328-9ef3cc74078a.png">

文のある位置にくる単語は{to, two, too} のような似た単語のうちどれが正しいかを予測するような分類において、4つのアルゴリズムを試した結果、どのアルゴリズムでもデータが増えるほど良い結果になることがわかった。「良いアルゴリズムよりも多くのデータが大事」

### 大量データの論理的根拠

<img width="963" alt="2016-08-08 14 18 51" src="https://cloud.githubusercontent.com/assets/6447085/17469945/109dff44-5d73-11e6-8977-fbf73dfff8b2.png">

大量のデータが有効である条件は十分なフィーチャーがあること。家の価格を予測するのに土地のサイズしか知らなければ正確に予測するのは困難である。

フィーチャーの量が十分かどうかのテストとして、その分野のプロが実際にそのフィーチャーを使って答えを予測できるかどうかを想像するということがある。

### 大量データの論理的根拠

<img width="960" alt="2016-08-08 14 19 41" src="https://cloud.githubusercontent.com/assets/6447085/17469956/2e482272-5d73-11e6-838a-1cd223f09baa.png">

フィーチャーが十分にあり、多くのパラメータを使えるアルゴリズムは、複雑な関数にフィットすることができるので、低バイアスアルゴリズムであり、トレーニングセットにも良くフィットし $J_{train}\(theta)$ は小さくなる。

大量のデータがあればどんなパラメータであってもオーバーフィットしづらくなる。そしてトレーニング誤差とテスト誤差は非常に小さくなる。

以上のことからテストセットの誤差も小さくなることが期待できる。別の考え方として、高バイアスを避けるためパラメータを増やし、高バリアンスを避けるためトレーニングセットを大量に用意することで低バイアス低バリアンスな学習アルゴリズムを得られる。
