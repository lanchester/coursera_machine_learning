## 仮説の評価

### 仮説を評価する

![2016-08-01 15 28 57](https://cloud.githubusercontent.com/assets/6447085/17285263/b13c0d46-57fc-11e6-995a-c7a6c068e2fc.png)

トレーニングセットによって学習された仮説はオーバーフィッティングしている可能性がある。このオーバーフィッティングを検知する必要がある。

### 仮説を評価する

![2016-08-01 15 29 32](https://cloud.githubusercontent.com/assets/6447085/17285276/c56d9b36-57fc-11e6-8168-1161eb4f9900.png)

仮説の評価のためにデータセットを2つにわける。片方をトレーニングセットとし、もう片方をテストセットとする。比率は7:3程度。もしデータが順序だっているならテストセットはランダムに選択する。

### 線形回帰のトレーニング/テスト手順

![2016-08-01 15 30 35](https://cloud.githubusercontent.com/assets/6447085/17285298/ea9cdce6-57fc-11e6-9ea0-0bfa2f6937c5.png)

まずトレーニングセットで $\theta$ を決定する。次にテストセットで誤差を検知する。つまりテストセットについてのコスト関数を評価する。

### 分類のトレーニング/テスト手順

![2016-08-01 15 31 10](https://cloud.githubusercontent.com/assets/6447085/17285317/023cd7ac-57fd-11e6-8b29-b455c077a983.png)

線形回帰と同じ手順でテストセットのコスト関数を評価する。分類の場合、通常のコスト関数でも計算量は多くないが、代わりに0/1分類エラー関数を使うこともできる。つまり $h_\theta(x_{test}) > 0.5$ の時は1、 $h_\theta(x_{test}) \leq 0.5$ の時は0として $y \in {0,1}$ との誤差を比べる。(一番下の式)
