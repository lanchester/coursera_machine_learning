## PCAを適用するするために

### 教師あり学習の高速化

<img width="963" alt="2016-09-06 15 01 38" src="https://cloud.githubusercontent.com/assets/6447085/18263168/d5b89984-7442-11e6-931c-a47270403383.png">

実際にPCAを使って教師あり学習を高速化するにはトレーニングセットからラベルを抜いたフィーチャーのみを取りだし、これに対してPCAを実行する。そして得られたより低次元のフィーチャーベクトル $z^{(i)}$ で元のトレーニングセットの $x^{(i)}$ を置き換える。

またPCAはトレーニングセットにのみに適用する。PCAで定義される $U_{reduce}$ も学習されるため。トレーニングセットで定義されたxからzへのマッピングをクロスバリデーションセットやテストセットに適用するべきである。

またPCAはトレーニングセットにのみに適用する。PCAで定義される $U_{reduce}$ も学習されるため。トレーニングセットで定義されたxからzへのマッピングをクロスバリデーションセットやテストセットに適用するべきである。

実際のデータでは分類精度を保ったまま多くの次元を削減できることが多い。

### PCA応用例

<img width="963" alt="2016-09-06 15 03 25" src="https://cloud.githubusercontent.com/assets/6447085/18263201/1a66a652-7443-11e6-9d69-712f490c673b.png">

PCAは以下の目的に使うことができる。

#### 圧縮
- メモリ、ディスク容量の削減
- 学習の高速化
この場合kは分散保持率が99%以上になるような値を選ぶ。

#### 可視化
kを2か3にすることでグラフにプロットすることができるようになる。

### PCAの誤った使い方: オーバーフィッティングを防ぐ

<img width="960" alt="2016-09-06 15 02 06" src="https://cloud.githubusercontent.com/assets/6447085/18263176/e6f44fe0-7442-11e6-99e6-1160c664399e.png">

PCAをオーバーフィッティング防止のために使うのは誤り。PCAはラベルの値を考慮しないため削減された次元に重要な情報が含まれている可能性がある。とは言え99%以上の分散保持率があれば恐らく問題ないため適用しても上手くいくかもしれないが、それよりも正規化項で調整するほうが良い。

### PCAは時々誤用される

<img width="963" alt="2016-09-06 15 04 04" src="https://cloud.githubusercontent.com/assets/6447085/18263209/2ec18658-7443-11e6-8ab8-6bcd76d68750.png">

PCAは最初から適用すべきではない。まず元のフィーチャーで学習を試し、速度が遅い、メモリ・ディスクを使いすぎている、などの理由があって始めて適用を検討するべき。
